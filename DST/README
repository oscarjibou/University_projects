```markdown
# Proyecto de Machine Learning - Clasificación de Audio

Este repositorio contiene un proyecto de Machine Learning enfocado en la clasificación de señales de audio utilizando redes neuronales convolucionales. El proyecto está implementado en Python y hace uso de varias librerías como `torch`, `librosa`, y `numpy`.

## Descripción del Proyecto

Este proyecto tiene como objetivo detectar y clasificar segmentos de audio mediante la extracción de características y el uso de modelos de deep learning. El flujo general del proyecto incluye:

1. **Preprocesamiento del Audio**: Lectura, normalización y resampleo de archivos de audio.
2. **Extracción de Características**: Obtención de espectrogramas a partir de los archivos de audio.
3. **Construcción del Modelo**: Implementación de una red neuronal convolucional para la clasificación.
4. **Entrenamiento del Modelo**: Entrenamiento del modelo con datos preprocesados.
5. **Evaluación y Pruebas**: Evaluación del modelo y pruebas con grabaciones en tiempo real.

## Estructura del Proyecto

- `utils.py`: Contiene funciones auxiliares para el procesamiento de audio.
- `main.py`: Script principal para ejecutar las etapas del proyecto.
- `notebooks/`: Directorio que contiene Jupyter notebooks con experimentos y visualizaciones.
- `data/`: Directorio para almacenar los archivos de audio y datos de entrenamiento.
- `models/`: Directorio para guardar los modelos entrenados.

## Requisitos

Para ejecutar este proyecto, necesitarás tener instaladas las siguientes librerías de Python:

- `torch`
- `librosa`
- `numpy`
- `pandas`
- `scipy`
- `matplotlib`
- `tqdm`
- `pytest`

Puedes instalar todos los requisitos utilizando el archivo `requirements.txt` proporcionado:

```bash
pip install -r requirements.txt
```

## Uso del Proyecto

### 1. Preprocesamiento del Audio

El primer paso es preprocesar los archivos de audio. Esto incluye la normalización y el resampleo de los archivos para asegurarse de que todos tengan la misma frecuencia de muestreo.

```python
from utils import preprocess_audio

audio_path = 'ruta/al/audio.wav'
audio_data, sample_rate = preprocess_audio(audio_path)
```

### 2. Extracción de Espectrogramas

Se extraen espectrogramas a partir de los archivos de audio para ser utilizados como características de entrada al modelo.

```python
from utils import extract_spectrogram

spectrogram = extract_spectrogram(audio_data, sample_rate)
```

### 3. Construcción del Modelo

Se define una red neuronal convolucional utilizando PyTorch. El modelo se puede personalizar ajustando los hiperparámetros.

```python
import torch
from torch import nn

class AudioClassifier(nn.Module):
    def __init__(self, num_classes):
        super(AudioClassifier, self).__init__()
        # Definición de las capas del modelo
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(16)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool2d(2)
        self.fc = nn.Linear(16*16*16, num_classes)

    def forward(self, x):
        x = self.pool(self.relu(self.bn1(self.conv1(x))))
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x
```

### 4. Entrenamiento del Modelo

Se entrena el modelo utilizando un conjunto de datos preprocesados.

```python
from torch.utils.data import DataLoader, TensorDataset

# Crear dataset y dataloader
train_dataset = TensorDataset(spectrograms, labels)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# Definir el loop de entrenamiento
def train(model, train_loader, criterion, optimizer, num_epochs):
    for epoch in range(num_epochs):
        for data, target in train_loader:
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

# Inicializar y entrenar el modelo
model = AudioClassifier(num_classes=10)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
train(model, train_loader, criterion, optimizer, num_epochs=10)
```

### 5. Evaluación y Pruebas

Una vez entrenado el modelo, se puede evaluar su rendimiento y realizar pruebas con grabaciones en tiempo real.
